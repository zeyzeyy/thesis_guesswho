{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets \n",
    "import pandas as pd \n",
    "v2w_add = pd.read_csv(\"data/word2vec-data.csv\")\n",
    "v2w_avg = pd.read_csv(\"data/word2vec-avg-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec addition analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = v2w_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing before the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['question', 'FaceID'])\n",
    "df = df.astype('category')\n",
    "\n",
    "df['true_answer'] = df['true_answer'].cat.codes\n",
    "df['gender'] = df['gender'].cat.codes\n",
    "df['hair'] = df['hair'].cat.codes\n",
    "df['eyes'] = df['eyes'].cat.codes\n",
    "df['ethnicity'] = df['ethnicity'].cat.codes\n",
    "df['age'] = df['age'].cat.codes\n",
    "\n",
    "df = pd.DataFrame(df, dtype = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset according to the features and the target \n",
    "y = df[\"true_answer\"]\n",
    "X = df.drop(columns = [\"true_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.95)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the train and test sets with 80:20 ratio for the classification models \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=0.2, random_state= 2345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5729440357330531\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print(logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28032  5855]\n",
      " [20151  6858]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.674025\n",
      "         Iterations 5\n",
      "                          Results: Logit\n",
      "==================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.018      \n",
      "Dependent Variable: true_answer      AIC:              411064.0188\n",
      "Date:               2018-12-27 16:13 BIC:              414305.0588\n",
      "No. Observations:   304480           Log-Likelihood:   -2.0523e+05\n",
      "Df Model:           304              LL-Null:          -2.0907e+05\n",
      "Df Residuals:       304175           LLR p-value:      0.0000     \n",
      "Converged:          1.0000           Scale:            1.0000     \n",
      "No. Iterations:     5.0000                                        \n",
      "-------------------------------------------------------------------\n",
      "               Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
      "-------------------------------------------------------------------\n",
      "hair          -0.0296    0.0031   -9.4761  0.0000  -0.0357  -0.0235\n",
      "eyes          -0.0406    0.0046   -8.8908  0.0000  -0.0495  -0.0316\n",
      "age           -0.0207    0.0055   -3.7496  0.0002  -0.0316  -0.0099\n",
      "ethnicity      0.0304    0.0045    6.7622  0.0000   0.0216   0.0392\n",
      "gender         0.0587    0.0074    7.9185  0.0000   0.0441   0.0732\n",
      "wv1            0.0274    0.0717    0.3815  0.7028  -0.1132   0.1679\n",
      "wv2            0.1857    0.0753    2.4653  0.0137   0.0381   0.3334\n",
      "wv3            0.2663    0.0673    3.9579  0.0001   0.1344   0.3982\n",
      "wv4            0.4639    0.0711    6.5270  0.0000   0.3246   0.6032\n",
      "wv5            0.2221    0.0748    2.9685  0.0030   0.0755   0.3688\n",
      "wv6           -0.0292    0.0661   -0.4425  0.6582  -0.1587   0.1003\n",
      "wv7           -0.1389    0.0697   -1.9926  0.0463  -0.2755  -0.0023\n",
      "wv8            0.2974    0.0668    4.4525  0.0000   0.1665   0.4282\n",
      "wv9           -0.2103    0.0688   -3.0553  0.0022  -0.3451  -0.0754\n",
      "wv10           0.0341    0.0736    0.4638  0.6428  -0.1101   0.1783\n",
      "wv11          -0.0363    0.0683   -0.5311  0.5953  -0.1701   0.0976\n",
      "wv12           0.2266    0.0736    3.0794  0.0021   0.0824   0.3709\n",
      "wv13           0.2875    0.0692    4.1534  0.0000   0.1518   0.4232\n",
      "wv14          -0.1985    0.0662   -2.9983  0.0027  -0.3283  -0.0688\n",
      "wv15          -0.1932    0.0684   -2.8233  0.0048  -0.3274  -0.0591\n",
      "wv16           0.2505    0.0691    3.6235  0.0003   0.1150   0.3860\n",
      "wv17          -0.2050    0.0679   -3.0192  0.0025  -0.3380  -0.0719\n",
      "wv18          -0.2665    0.0669   -3.9802  0.0001  -0.3977  -0.1353\n",
      "wv19           0.0210    0.0669    0.3135  0.7539  -0.1101   0.1521\n",
      "wv20          -0.2349    0.0681   -3.4505  0.0006  -0.3683  -0.1015\n",
      "wv21          -0.5045    0.0729   -6.9255  0.0000  -0.6473  -0.3618\n",
      "wv22           0.0426    0.0704    0.6048  0.5453  -0.0954   0.1805\n",
      "wv23          -0.0260    0.0633   -0.4103  0.6816  -0.1500   0.0981\n",
      "wv24          -0.2191    0.0642   -3.4156  0.0006  -0.3449  -0.0934\n",
      "wv25           0.1154    0.0716    1.6105  0.1073  -0.0250   0.2557\n",
      "wv26           0.0648    0.0722    0.8975  0.3694  -0.0767   0.2064\n",
      "wv27           0.4215    0.0719    5.8589  0.0000   0.2805   0.5625\n",
      "wv28          -0.3011    0.0713   -4.2223  0.0000  -0.4408  -0.1613\n",
      "wv29          -0.1501    0.0677   -2.2170  0.0266  -0.2828  -0.0174\n",
      "wv30          -0.2963    0.0706   -4.1998  0.0000  -0.4346  -0.1580\n",
      "wv31          -0.1958    0.0670   -2.9226  0.0035  -0.3271  -0.0645\n",
      "wv32          -0.0208    0.0647   -0.3214  0.7479  -0.1475   0.1059\n",
      "wv33          -0.0020    0.0684   -0.0291  0.9767  -0.1360   0.1320\n",
      "wv34          -0.0151    0.0662   -0.2278  0.8198  -0.1448   0.1146\n",
      "wv35           0.1086    0.0699    1.5552  0.1199  -0.0283   0.2455\n",
      "wv36          -0.2749    0.0658   -4.1760  0.0000  -0.4040  -0.1459\n",
      "wv37          -0.1727    0.0732   -2.3585  0.0183  -0.3162  -0.0292\n",
      "wv38          -0.1379    0.0658   -2.0940  0.0363  -0.2669  -0.0088\n",
      "wv39           0.2084    0.0660    3.1582  0.0016   0.0791   0.3377\n",
      "wv40           0.2160    0.0714    3.0241  0.0025   0.0760   0.3559\n",
      "wv41          -0.1980    0.0673   -2.9407  0.0033  -0.3300  -0.0660\n",
      "wv42          -0.0642    0.0677   -0.9489  0.3427  -0.1968   0.0684\n",
      "wv43           0.2453    0.0683    3.5903  0.0003   0.1114   0.3793\n",
      "wv44          -0.1678    0.0727   -2.3077  0.0210  -0.3102  -0.0253\n",
      "wv45           0.1404    0.0707    1.9871  0.0469   0.0019   0.2790\n",
      "wv46          -0.0882    0.0693   -1.2736  0.2028  -0.2239   0.0475\n",
      "wv47           0.0563    0.0707    0.7963  0.4258  -0.0822   0.1948\n",
      "wv48           0.1522    0.0670    2.2737  0.0230   0.0210   0.2835\n",
      "wv49          -0.0442    0.0692   -0.6393  0.5226  -0.1798   0.0914\n",
      "wv50           0.2911    0.0719    4.0476  0.0001   0.1501   0.4321\n",
      "wv51          -0.1330    0.0637   -2.0869  0.0369  -0.2579  -0.0081\n",
      "wv52           0.1024    0.0673    1.5211  0.1282  -0.0295   0.2343\n",
      "wv53          -0.0537    0.0719   -0.7468  0.4552  -0.1946   0.0872\n",
      "wv54          -0.0072    0.0698   -0.1035  0.9176  -0.1440   0.1296\n",
      "wv55          -0.1970    0.0741   -2.6598  0.0078  -0.3421  -0.0518\n",
      "wv56           0.1069    0.0633    1.6875  0.0915  -0.0173   0.2310\n",
      "wv57           0.1167    0.0672    1.7369  0.0824  -0.0150   0.2483\n",
      "wv58          -0.2306    0.0664   -3.4711  0.0005  -0.3608  -0.1004\n",
      "wv59           0.2900    0.0746    3.8883  0.0001   0.1438   0.4361\n",
      "wv60          -0.2515    0.0764   -3.2912  0.0010  -0.4013  -0.1017\n",
      "wv61           0.1177    0.0722    1.6313  0.1028  -0.0237   0.2591\n",
      "wv62           0.3565    0.0627    5.6836  0.0000   0.2336   0.4794\n",
      "wv63           0.1321    0.0708    1.8661  0.0620  -0.0066   0.2709\n",
      "wv64          -0.1920    0.0643   -2.9883  0.0028  -0.3179  -0.0661\n",
      "wv65          -0.1914    0.0680   -2.8133  0.0049  -0.3248  -0.0581\n",
      "wv66          -0.1607    0.0773   -2.0786  0.0377  -0.3123  -0.0092\n",
      "wv67           0.2676    0.0665    4.0221  0.0001   0.1372   0.3980\n",
      "wv68          -0.0771    0.0684   -1.1279  0.2593  -0.2111   0.0569\n",
      "wv69           0.3227    0.0698    4.6259  0.0000   0.1860   0.4594\n",
      "wv70          -0.0273    0.0693   -0.3937  0.6938  -0.1631   0.1086\n",
      "wv71          -0.4275    0.0699   -6.1118  0.0000  -0.5646  -0.2904\n",
      "wv72          -0.0941    0.0685   -1.3727  0.1699  -0.2284   0.0402\n",
      "wv73           0.2552    0.0722    3.5353  0.0004   0.1137   0.3966\n",
      "wv74           0.0016    0.0675    0.0235  0.9813  -0.1308   0.1339\n",
      "wv75           0.0173    0.0694    0.2492  0.8032  -0.1187   0.1532\n",
      "wv76          -0.4169    0.0644   -6.4706  0.0000  -0.5432  -0.2906\n",
      "wv77           0.4007    0.0706    5.6775  0.0000   0.2624   0.5391\n",
      "wv78          -0.1147    0.0691   -1.6585  0.0972  -0.2501   0.0208\n",
      "wv79          -0.0271    0.0694   -0.3899  0.6966  -0.1632   0.1090\n",
      "wv80          -0.1096    0.0659   -1.6623  0.0964  -0.2388   0.0196\n",
      "wv81          -0.0086    0.0761   -0.1136  0.9096  -0.1577   0.1405\n",
      "wv82           0.1182    0.0761    1.5530  0.1204  -0.0310   0.2674\n",
      "wv83          -0.2517    0.0641   -3.9258  0.0001  -0.3774  -0.1260\n",
      "wv84          -0.0583    0.0674   -0.8649  0.3871  -0.1904   0.0738\n",
      "wv85          -0.0777    0.0635   -1.2229  0.2214  -0.2021   0.0468\n",
      "wv86          -0.0772    0.0674   -1.1455  0.2520  -0.2094   0.0549\n",
      "wv87           0.0480    0.0652    0.7352  0.4622  -0.0799   0.1758\n",
      "wv88          -0.2358    0.0719   -3.2808  0.0010  -0.3767  -0.0949\n",
      "wv89          -0.0057    0.0718   -0.0798  0.9364  -0.1465   0.1350\n",
      "wv90           0.0791    0.0683    1.1570  0.2473  -0.0549   0.2130\n",
      "wv91          -0.6489    0.0717   -9.0530  0.0000  -0.7894  -0.5084\n",
      "wv92          -0.0870    0.0729   -1.1933  0.2328  -0.2300   0.0559\n",
      "wv93           0.3828    0.0710    5.3915  0.0000   0.2436   0.5219\n",
      "wv94          -0.2867    0.0722   -3.9688  0.0001  -0.4282  -0.1451\n",
      "wv95           0.0846    0.0730    1.1592  0.2464  -0.0585   0.2277\n",
      "wv96          -0.3862    0.0741   -5.2122  0.0000  -0.5315  -0.2410\n",
      "wv97           0.0480    0.0709    0.6761  0.4990  -0.0911   0.1870\n",
      "wv98          -0.0548    0.0713   -0.7677  0.4427  -0.1946   0.0851\n",
      "wv99           0.0434    0.0703    0.6165  0.5376  -0.0945   0.1812\n",
      "wv100         -0.0415    0.0676   -0.6133  0.5397  -0.1739   0.0910\n",
      "wv101         -0.7770    0.0712  -10.9183  0.0000  -0.9165  -0.6375\n",
      "wv102          0.0987    0.0699    1.4116  0.1581  -0.0383   0.2357\n",
      "wv103         -0.1355    0.0660   -2.0516  0.0402  -0.2649  -0.0060\n",
      "wv104         -0.2527    0.0681   -3.7113  0.0002  -0.3861  -0.1192\n",
      "wv105          0.2079    0.0661    3.1446  0.0017   0.0783   0.3374\n",
      "wv106         -0.0398    0.0721   -0.5518  0.5811  -0.1811   0.1015\n",
      "wv107          0.1584    0.0653    2.4275  0.0152   0.0305   0.2863\n",
      "wv108         -0.1000    0.0699   -1.4322  0.1521  -0.2369   0.0369\n",
      "wv109          0.2086    0.0698    2.9889  0.0028   0.0718   0.3454\n",
      "wv110          0.1010    0.0717    1.4084  0.1590  -0.0395   0.2415\n",
      "wv111          0.1222    0.0680    1.7983  0.0721  -0.0110   0.2554\n",
      "wv112         -0.3522    0.0607   -5.7994  0.0000  -0.4713  -0.2332\n",
      "wv113         -0.1460    0.0702   -2.0809  0.0374  -0.2836  -0.0085\n",
      "wv114          0.0190    0.0742    0.2566  0.7975  -0.1264   0.1645\n",
      "wv115          0.2721    0.0654    4.1590  0.0000   0.1439   0.4004\n",
      "wv116          0.1344    0.0742    1.8107  0.0702  -0.0111   0.2798\n",
      "wv117         -0.2656    0.0717   -3.7038  0.0002  -0.4062  -0.1251\n",
      "wv118          0.2718    0.0707    3.8450  0.0001   0.1332   0.4103\n",
      "wv119         -0.1932    0.0707   -2.7322  0.0063  -0.3318  -0.0546\n",
      "wv120          0.3815    0.0713    5.3500  0.0000   0.2417   0.5212\n",
      "wv121          0.0268    0.0696    0.3845  0.7006  -0.1097   0.1632\n",
      "wv122          0.2499    0.0708    3.5325  0.0004   0.1113   0.3886\n",
      "wv123          0.1539    0.0669    2.3016  0.0214   0.0228   0.2850\n",
      "wv124          0.1412    0.0669    2.1125  0.0346   0.0102   0.2723\n",
      "wv125         -0.4084    0.0680   -6.0068  0.0000  -0.5417  -0.2751\n",
      "wv126          0.3132    0.0661    4.7370  0.0000   0.1836   0.4427\n",
      "wv127         -0.4221    0.0682   -6.1859  0.0000  -0.5558  -0.2884\n",
      "wv128          0.0360    0.0719    0.5005  0.6167  -0.1049   0.1768\n",
      "wv129          0.1038    0.0721    1.4392  0.1501  -0.0375   0.2450\n",
      "wv130          0.1273    0.0714    1.7838  0.0745  -0.0126   0.2672\n",
      "wv131          0.2850    0.0726    3.9261  0.0001   0.1427   0.4272\n",
      "wv132         -0.6500    0.0714   -9.1031  0.0000  -0.7899  -0.5100\n",
      "wv133          0.1106    0.0681    1.6231  0.1046  -0.0230   0.2442\n",
      "wv134          0.2807    0.0765    3.6708  0.0002   0.1308   0.4305\n",
      "wv135          0.2142    0.0728    2.9418  0.0033   0.0715   0.3569\n",
      "wv136         -0.0617    0.0706   -0.8731  0.3826  -0.2001   0.0768\n",
      "wv137         -0.4087    0.0754   -5.4196  0.0000  -0.5565  -0.2609\n",
      "wv138         -0.0153    0.0697   -0.2193  0.8265  -0.1519   0.1213\n",
      "wv139          0.1660    0.0718    2.3112  0.0208   0.0252   0.3068\n",
      "wv140          0.0141    0.0642    0.2195  0.8263  -0.1117   0.1399\n",
      "wv141          0.0775    0.0703    1.1022  0.2704  -0.0603   0.2153\n",
      "wv142          0.3463    0.0669    5.1749  0.0000   0.2151   0.4775\n",
      "wv143         -0.4119    0.0693   -5.9390  0.0000  -0.5478  -0.2759\n",
      "wv144          0.1316    0.0688    1.9129  0.0558  -0.0032   0.2664\n",
      "wv145          0.2457    0.0687    3.5767  0.0003   0.1110   0.3803\n",
      "wv146          0.4461    0.0639    6.9825  0.0000   0.3209   0.5713\n",
      "wv147         -0.0032    0.0772   -0.0417  0.9668  -0.1544   0.1480\n",
      "wv148          0.1005    0.0670    1.4987  0.1340  -0.0309   0.2318\n",
      "wv149         -0.0601    0.0665   -0.9032  0.3664  -0.1904   0.0703\n",
      "wv150         -0.2859    0.0716   -3.9908  0.0001  -0.4263  -0.1455\n",
      "wv151         -0.1488    0.0685   -2.1730  0.0298  -0.2830  -0.0146\n",
      "wv152         -0.3191    0.0718   -4.4458  0.0000  -0.4598  -0.1784\n",
      "wv153          0.0606    0.0652    0.9295  0.3526  -0.0672   0.1885\n",
      "wv154          0.1847    0.0664    2.7839  0.0054   0.0547   0.3148\n",
      "wv155         -0.0502    0.0691   -0.7256  0.4681  -0.1856   0.0853\n",
      "wv156          0.0671    0.0693    0.9671  0.3335  -0.0688   0.2029\n",
      "wv157          0.1608    0.0735    2.1881  0.0287   0.0168   0.3049\n",
      "wv158         -0.0066    0.0671   -0.0981  0.9218  -0.1381   0.1249\n",
      "wv159          0.1663    0.0702    2.3695  0.0178   0.0287   0.3038\n",
      "wv160         -0.0981    0.0695   -1.4119  0.1580  -0.2342   0.0381\n",
      "wv161          0.2098    0.0686    3.0573  0.0022   0.0753   0.3443\n",
      "wv162         -0.1274    0.0700   -1.8191  0.0689  -0.2646   0.0099\n",
      "wv163          0.1332    0.0698    1.9073  0.0565  -0.0037   0.2701\n",
      "wv164          0.1133    0.0653    1.7353  0.0827  -0.0147   0.2414\n",
      "wv165         -0.0180    0.0737   -0.2439  0.8073  -0.1625   0.1266\n",
      "wv166          0.0471    0.0715    0.6579  0.5106  -0.0931   0.1872\n",
      "wv167         -0.1133    0.0738   -1.5346  0.1249  -0.2580   0.0314\n",
      "wv168          0.1014    0.0685    1.4792  0.1391  -0.0329   0.2357\n",
      "wv169         -0.2416    0.0717   -3.3683  0.0008  -0.3822  -0.1010\n",
      "wv170         -0.3333    0.0720   -4.6313  0.0000  -0.4744  -0.1923\n",
      "wv171          0.0640    0.0616    1.0397  0.2985  -0.0567   0.1847\n",
      "wv172         -0.1674    0.0700   -2.3924  0.0167  -0.3046  -0.0303\n",
      "wv173          0.2807    0.0673    4.1684  0.0000   0.1487   0.4127\n",
      "wv174          0.1493    0.0759    1.9666  0.0492   0.0005   0.2980\n",
      "wv175          0.1288    0.0753    1.7094  0.0874  -0.0189   0.2764\n",
      "wv176         -0.2104    0.0680   -3.0957  0.0020  -0.3436  -0.0772\n",
      "wv177         -0.2135    0.0700   -3.0517  0.0023  -0.3506  -0.0764\n",
      "wv178         -0.2179    0.0661   -3.2961  0.0010  -0.3474  -0.0883\n",
      "wv179          0.4659    0.0636    7.3287  0.0000   0.3413   0.5905\n",
      "wv180          0.3364    0.0696    4.8345  0.0000   0.2000   0.4728\n",
      "wv181          0.1904    0.0780    2.4417  0.0146   0.0376   0.3433\n",
      "wv182         -0.1850    0.0675   -2.7422  0.0061  -0.3173  -0.0528\n",
      "wv183          0.0677    0.0719    0.9416  0.3464  -0.0732   0.2086\n",
      "wv184         -0.0149    0.0763   -0.1956  0.8449  -0.1644   0.1345\n",
      "wv185         -0.0628    0.0638   -0.9838  0.3252  -0.1879   0.0623\n",
      "wv186         -0.3530    0.0688   -5.1306  0.0000  -0.4878  -0.2181\n",
      "wv187          0.3314    0.0684    4.8442  0.0000   0.1973   0.4655\n",
      "wv188          0.3079    0.0788    3.9084  0.0001   0.1535   0.4624\n",
      "wv189         -0.1240    0.0679   -1.8267  0.0677  -0.2570   0.0090\n",
      "wv190          0.1107    0.0659    1.6802  0.0929  -0.0184   0.2398\n",
      "wv191         -0.1111    0.0697   -1.5941  0.1109  -0.2478   0.0255\n",
      "wv192         -0.1636    0.0750   -2.1828  0.0291  -0.3105  -0.0167\n",
      "wv193         -0.0278    0.0688   -0.4037  0.6864  -0.1625   0.1070\n",
      "wv194         -0.1147    0.0703   -1.6314  0.1028  -0.2526   0.0231\n",
      "wv195          0.1862    0.0667    2.7933  0.0052   0.0556   0.3169\n",
      "wv196         -0.1103    0.0704   -1.5672  0.1171  -0.2483   0.0277\n",
      "wv197         -0.1623    0.0683   -2.3774  0.0174  -0.2961  -0.0285\n",
      "wv198         -0.1534    0.0667   -2.2996  0.0215  -0.2841  -0.0227\n",
      "wv199         -0.3209    0.0689   -4.6557  0.0000  -0.4560  -0.1858\n",
      "wv200          0.3241    0.0718    4.5138  0.0000   0.1834   0.4649\n",
      "wv201         -0.1553    0.0732   -2.1224  0.0338  -0.2987  -0.0119\n",
      "wv202         -0.1968    0.0718   -2.7402  0.0061  -0.3376  -0.0561\n",
      "wv203         -0.0900    0.0668   -1.3480  0.1776  -0.2210   0.0409\n",
      "wv204          0.3486    0.0701    4.9717  0.0000   0.2112   0.4860\n",
      "wv205         -0.1060    0.0683   -1.5513  0.1208  -0.2400   0.0279\n",
      "wv206         -0.1252    0.0665   -1.8810  0.0600  -0.2556   0.0053\n",
      "wv207          0.5054    0.0729    6.9321  0.0000   0.3625   0.6483\n",
      "wv208          0.0992    0.0710    1.3970  0.1624  -0.0400   0.2383\n",
      "wv209         -0.2903    0.0709   -4.0970  0.0000  -0.4292  -0.1514\n",
      "wv210          0.0889    0.0755    1.1766  0.2394  -0.0592   0.2370\n",
      "wv211          0.1807    0.0639    2.8253  0.0047   0.0553   0.3060\n",
      "wv212          0.0224    0.0650    0.3452  0.7299  -0.1049   0.1498\n",
      "wv213         -0.0240    0.0677   -0.3548  0.7227  -0.1567   0.1086\n",
      "wv214          0.0723    0.0638    1.1326  0.2574  -0.0528   0.1974\n",
      "wv215         -0.0314    0.0710   -0.4416  0.6588  -0.1706   0.1078\n",
      "wv216          0.3114    0.0673    4.6257  0.0000   0.1794   0.4433\n",
      "wv217         -0.0073    0.0685   -0.1069  0.9149  -0.1417   0.1270\n",
      "wv218          0.0194    0.0656    0.2950  0.7680  -0.1093   0.1480\n",
      "wv219         -0.0539    0.0692   -0.7790  0.4360  -0.1896   0.0817\n",
      "wv220          0.1076    0.0680    1.5817  0.1137  -0.0257   0.2410\n",
      "wv221          0.0845    0.0736    1.1477  0.2511  -0.0598   0.2287\n",
      "wv222         -0.0032    0.0634   -0.0498  0.9602  -0.1275   0.1211\n",
      "wv223          0.0625    0.0706    0.8854  0.3759  -0.0759   0.2009\n",
      "wv224          0.0360    0.0714    0.5035  0.6146  -0.1040   0.1760\n",
      "wv225         -0.0598    0.0660   -0.9061  0.3649  -0.1892   0.0696\n",
      "wv226         -0.2096    0.0773   -2.7096  0.0067  -0.3612  -0.0580\n",
      "wv227         -0.1016    0.0725   -1.4005  0.1614  -0.2438   0.0406\n",
      "wv228         -0.1860    0.0622   -2.9898  0.0028  -0.3079  -0.0641\n",
      "wv229          0.3916    0.0700    5.5910  0.0000   0.2543   0.5288\n",
      "wv230         -0.1576    0.0676   -2.3304  0.0198  -0.2901  -0.0251\n",
      "wv231         -0.1780    0.0717   -2.4829  0.0130  -0.3186  -0.0375\n",
      "wv232         -0.0910    0.0690   -1.3186  0.1873  -0.2263   0.0443\n",
      "wv233          0.2618    0.0716    3.6549  0.0003   0.1214   0.4022\n",
      "wv234         -0.3256    0.0733   -4.4407  0.0000  -0.4694  -0.1819\n",
      "wv235          0.3039    0.0689    4.4124  0.0000   0.1689   0.4389\n",
      "wv236          0.1276    0.0670    1.9039  0.0569  -0.0038   0.2590\n",
      "wv237          0.1651    0.0678    2.4362  0.0148   0.0323   0.2979\n",
      "wv238         -0.1079    0.0774   -1.3934  0.1635  -0.2597   0.0439\n",
      "wv239          0.1992    0.0776    2.5677  0.0102   0.0471   0.3512\n",
      "wv240          0.0067    0.0708    0.0950  0.9243  -0.1320   0.1454\n",
      "wv241         -0.2393    0.0656   -3.6493  0.0003  -0.3678  -0.1108\n",
      "wv242          0.1351    0.0673    2.0083  0.0446   0.0033   0.2670\n",
      "wv243         -0.3179    0.0633   -5.0249  0.0000  -0.4419  -0.1939\n",
      "wv244         -0.2454    0.0670   -3.6632  0.0002  -0.3767  -0.1141\n",
      "wv245          0.2689    0.0688    3.9089  0.0001   0.1340   0.4037\n",
      "wv246          0.1369    0.0680    2.0130  0.0441   0.0036   0.2702\n",
      "wv247         -0.1212    0.0756   -1.6036  0.1088  -0.2693   0.0269\n",
      "wv248          0.3017    0.0712    4.2358  0.0000   0.1621   0.4413\n",
      "wv249         -0.0500    0.0633   -0.7900  0.4295  -0.1741   0.0741\n",
      "wv250          0.2421    0.0727    3.3299  0.0009   0.0996   0.3846\n",
      "wv251          0.2154    0.0760    2.8329  0.0046   0.0664   0.3644\n",
      "wv252          0.0804    0.0723    1.1125  0.2659  -0.0613   0.2221\n",
      "wv253          0.0084    0.0731    0.1151  0.9084  -0.1349   0.1518\n",
      "wv254          0.1067    0.0658    1.6202  0.1052  -0.0224   0.2357\n",
      "wv255         -0.1359    0.0717   -1.8965  0.0579  -0.2764   0.0045\n",
      "wv256          0.3825    0.0702    5.4479  0.0000   0.2449   0.5202\n",
      "wv257          0.0928    0.0727    1.2762  0.2019  -0.0497   0.2352\n",
      "wv258          0.2861    0.0656    4.3635  0.0000   0.1576   0.4146\n",
      "wv259          0.0315    0.0706    0.4464  0.6553  -0.1069   0.1700\n",
      "wv260         -0.0444    0.0672   -0.6607  0.5088  -0.1762   0.0873\n",
      "wv261         -0.3301    0.0711   -4.6413  0.0000  -0.4695  -0.1907\n",
      "wv262         -0.4623    0.0704   -6.5702  0.0000  -0.6002  -0.3244\n",
      "wv263          0.0004    0.0676    0.0056  0.9955  -0.1321   0.1329\n",
      "wv264          0.1819    0.0581    3.1296  0.0018   0.0680   0.2957\n",
      "wv265          0.0790    0.0708    1.1163  0.2643  -0.0597   0.2177\n",
      "wv266         -0.0782    0.0730   -1.0712  0.2841  -0.2213   0.0649\n",
      "wv267          0.1207    0.0684    1.7652  0.0775  -0.0133   0.2546\n",
      "wv268         -0.3581    0.0707   -5.0628  0.0000  -0.4967  -0.2195\n",
      "wv269          0.0083    0.0679    0.1223  0.9027  -0.1247   0.1413\n",
      "wv270         -0.2195    0.0728   -3.0144  0.0026  -0.3621  -0.0768\n",
      "wv271         -0.0703    0.0707   -0.9941  0.3202  -0.2090   0.0683\n",
      "wv272          0.1539    0.0663    2.3190  0.0204   0.0238   0.2839\n",
      "wv273         -0.0590    0.0674   -0.8747  0.3817  -0.1911   0.0731\n",
      "wv274          0.1034    0.0681    1.5171  0.1292  -0.0302   0.2370\n",
      "wv275         -0.2097    0.0693   -3.0254  0.0025  -0.3456  -0.0739\n",
      "wv276         -0.0277    0.0699   -0.3968  0.6915  -0.1646   0.1092\n",
      "wv277          0.3877    0.0647    5.9955  0.0000   0.2609   0.5144\n",
      "wv278          0.3197    0.0674    4.7424  0.0000   0.1876   0.4518\n",
      "wv279          0.2522    0.0743    3.3940  0.0007   0.1066   0.3978\n",
      "wv280         -0.0279    0.0700   -0.3992  0.6897  -0.1651   0.1092\n",
      "wv281          0.2111    0.0686    3.0768  0.0021   0.0766   0.3456\n",
      "wv282          0.4301    0.0672    6.4025  0.0000   0.2985   0.5618\n",
      "wv283         -0.1158    0.0647   -1.7901  0.0734  -0.2427   0.0110\n",
      "wv284          0.0323    0.0696    0.4643  0.6424  -0.1041   0.1688\n",
      "wv285          0.0553    0.0713    0.7750  0.4383  -0.0845   0.1951\n",
      "wv286         -0.2687    0.0752   -3.5748  0.0004  -0.4160  -0.1214\n",
      "wv287         -0.0315    0.0686   -0.4599  0.6456  -0.1660   0.1029\n",
      "wv288          0.6546    0.0606   10.8060  0.0000   0.5359   0.7733\n",
      "wv289         -0.0412    0.0674   -0.6113  0.5410  -0.1732   0.0908\n",
      "wv290         -0.1595    0.0655   -2.4338  0.0149  -0.2880  -0.0311\n",
      "wv291         -0.0889    0.0658   -1.3516  0.1765  -0.2179   0.0400\n",
      "wv292          0.0816    0.0695    1.1741  0.2403  -0.0546   0.2178\n",
      "wv293         -0.1857    0.0768   -2.4176  0.0156  -0.3362  -0.0352\n",
      "wv294          0.2309    0.0733    3.1514  0.0016   0.0873   0.3744\n",
      "wv295          0.1640    0.0689    2.3805  0.0173   0.0290   0.2991\n",
      "wv296         -0.2124    0.0673   -3.1543  0.0016  -0.3443  -0.0804\n",
      "wv297         -0.1837    0.0676   -2.7161  0.0066  -0.3163  -0.0511\n",
      "wv298          0.0196    0.0686    0.2855  0.7753  -0.1149   0.1540\n",
      "wv299          0.0766    0.0660    1.1598  0.2461  -0.0528   0.2060\n",
      "wv300          0.1312    0.0644    2.0370  0.0416   0.0050   0.2573\n",
      "==================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555208880714662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "BernNB = BernoulliNB(binarize=True)\n",
    "BernNB.fit(X_train, y_train)\n",
    "\n",
    "y_expect = y_test\n",
    "y_pred = BernNB.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6462821860220704\n"
     ]
    }
   ],
   "source": [
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier with k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6534747766684182\n"
     ]
    }
   ],
   "source": [
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier with k = 7\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.52141546793523"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt(307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6695185233841303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(max_features = 17)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eyes         0.125212\n",
       "gender       0.123757\n",
       "age          0.123254\n",
       "hair         0.109224\n",
       "ethnicity    0.104678\n",
       "wv168        0.007017\n",
       "wv243        0.004615\n",
       "wv257        0.004117\n",
       "wv142        0.003923\n",
       "wv59         0.003722\n",
       "wv75         0.003643\n",
       "wv10         0.003471\n",
       "wv144        0.003359\n",
       "wv267        0.003304\n",
       "wv55         0.003188\n",
       "wv84         0.003010\n",
       "wv77         0.002963\n",
       "wv6          0.002932\n",
       "wv162        0.002923\n",
       "wv44         0.002813\n",
       "wv250        0.002766\n",
       "wv241        0.002738\n",
       "wv181        0.002693\n",
       "wv111        0.002641\n",
       "wv47         0.002625\n",
       "wv68         0.002596\n",
       "wv19         0.002488\n",
       "wv246        0.002487\n",
       "wv273        0.002472\n",
       "wv51         0.002449\n",
       "               ...   \n",
       "wv53         0.000865\n",
       "wv120        0.000857\n",
       "wv152        0.000851\n",
       "wv116        0.000847\n",
       "wv70         0.000846\n",
       "wv217        0.000846\n",
       "wv277        0.000832\n",
       "wv80         0.000826\n",
       "wv97         0.000824\n",
       "wv81         0.000819\n",
       "wv34         0.000813\n",
       "wv176        0.000811\n",
       "wv48         0.000803\n",
       "wv107        0.000798\n",
       "wv121        0.000797\n",
       "wv285        0.000795\n",
       "wv69         0.000785\n",
       "wv22         0.000782\n",
       "wv158        0.000771\n",
       "wv195        0.000755\n",
       "wv143        0.000754\n",
       "wv91         0.000745\n",
       "wv101        0.000744\n",
       "wv201        0.000738\n",
       "wv66         0.000737\n",
       "wv184        0.000733\n",
       "wv17         0.000706\n",
       "wv33         0.000683\n",
       "wv29         0.000636\n",
       "wv119        0.000614\n",
       "Length: 305, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=X.columns,).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec Average analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset \n",
    "df = v2w_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset for the classifiers\n",
    "\n",
    "df = df.drop(columns = ['question', 'FaceID'])\n",
    "df = df.astype('category')\n",
    "\n",
    "df['true_answer'] = df['true_answer'].cat.codes\n",
    "df['gender'] = df['gender'].cat.codes\n",
    "df['hair'] = df['hair'].cat.codes\n",
    "df['eyes'] = df['eyes'].cat.codes\n",
    "df['ethnicity'] = df['ethnicity'].cat.codes\n",
    "df['age'] = df['age'].cat.codes\n",
    "\n",
    "df = pd.DataFrame(df, dtype = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset according to the features and the target \n",
    "y = df[\"true_answer\"]\n",
    "X = df.drop(columns = [\"true_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.95)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the train and test sets with 80:20 ratio for the classification models \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=0.2, random_state= 2345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy score - word2vec average: 0.5671801103520757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Logistic regression accuracy score - word2vec average:\", logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27773  6114]\n",
      " [20243  6766]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy score - word2vec average 0.5564733315817131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "BernNB = BernoulliNB(binarize=True)\n",
    "BernNB.fit(X_train, y_train)\n",
    "\n",
    "y_expect = y_test\n",
    "y_pred = BernNB.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes accuracy score - word2vec average\", accuracy_score(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN - word2vec average, k = 5: 0.6241789280084078\n"
     ]
    }
   ],
   "source": [
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier with k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy KNN - word2vec average, k = 5:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN - word2vec average, k = 7: 0.6250164214398318\n"
     ]
    }
   ],
   "source": [
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier with k = 7\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy KNN - word2vec average, k = 7:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest - word2vec average: 0.6698797950604309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(max_features = 17)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy Random Forest - word2vec average:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "import pandas as pd \n",
    "ft_add = pd.read_csv(\"data/fasttext-data-add.csv\")\n",
    "ft_avg = pd.read_csv(\"data/fasttext-data-avg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fast text addition analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ft_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset for the classifiers\n",
    "\n",
    "df = df.drop(columns = ['question', 'FaceID'])\n",
    "df = df.astype('category')\n",
    "\n",
    "df['true_answer'] = df['true_answer'].cat.codes\n",
    "df['gender'] = df['gender'].cat.codes\n",
    "df['hair'] = df['hair'].cat.codes\n",
    "df['eyes'] = df['eyes'].cat.codes\n",
    "df['ethnicity'] = df['ethnicity'].cat.codes\n",
    "df['age'] = df['age'].cat.codes\n",
    "\n",
    "df = pd.DataFrame(df, dtype = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset according to the features and the target \n",
    "y = df[\"true_answer\"]\n",
    "X = df.drop(columns = [\"true_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.95)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the train and test sets with 80:20 ratio for the classification models \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=0.2, random_state= 2345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy score - fast text addition: 0.5789827948515892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Logistic regression accuracy score - fast text addition:\", logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "cm = confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Predicted versus True Label')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy score - fast text addition 0.5526497241922774\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "BernNB = BernoulliNB(binarize=True)\n",
    "BernNB.fit(X_train, y_train)\n",
    "\n",
    "y_expect = y_test\n",
    "y_pred = BernNB.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes accuracy score - fast text addition\", accuracy_score(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN - fast text addition, k = 5: 0.648460073548726\n"
     ]
    }
   ],
   "source": [
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier with k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy KNN - fast text addition, k = 5:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN - fast text addition, k = 7: 0.6533359600735488\n"
     ]
    }
   ],
   "source": [
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier with k = 7\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy KNN - fast text addition, k = 7:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN - fast text addition, k = 7: 0.6599356448647229\n"
     ]
    }
   ],
   "source": [
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier with k = 10\n",
    "knn = KNeighborsClassifier(n_neighbors= 10)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy KNN - fast text addition, k = 7:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(3, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.xlabel('k values')\n",
    "plt.ylabel('Accuracy ratios')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest - fast text addition: 0.6719858156028369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(max_features = 17)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy Random Forest - fast text addition:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fast text average analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ft_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset for the classifiers\n",
    "\n",
    "df = df.drop(columns = ['question', 'FaceID'])\n",
    "df = df.astype('category')\n",
    "\n",
    "df['true_answer'] = df['true_answer'].cat.codes\n",
    "df['gender'] = df['gender'].cat.codes\n",
    "df['hair'] = df['hair'].cat.codes\n",
    "df['eyes'] = df['eyes'].cat.codes\n",
    "df['ethnicity'] = df['ethnicity'].cat.codes\n",
    "df['age'] = df['age'].cat.codes\n",
    "\n",
    "df = pd.DataFrame(df, dtype = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset according to the features and the target \n",
    "y = df[\"true_answer\"]\n",
    "X = df.drop(columns = [\"true_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.95)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the train and test sets with 80:20 ratio for the classification models \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=0.2, random_state= 2345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy score - fast text average: 0.5732532177567639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Logistic regression accuracy score - fast text average:\", logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27970  5986]\n",
      " [20008  6948]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy score - fast text average 0.5574599422117152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "BernNB = BernoulliNB(binarize=True)\n",
    "BernNB.fit(X_train, y_train)\n",
    "\n",
    "y_expect = y_test\n",
    "y_pred = BernNB.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes accuracy score - fast text average\", accuracy_score(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN - fast text average, k = 5: 0.6152318098240084\n"
     ]
    }
   ],
   "source": [
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier with k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy KNN - fast text average, k = 5:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN - fast text average, k = 7: 0.6210270554242185\n"
     ]
    }
   ],
   "source": [
    "#Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier with k = 7\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy KNN - fast text average, k = 7:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest - fast text average: 0.675055818229577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(max_features = 17)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy Random Forest - fast text average:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest - fast text average: 0.6737752823745732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(max_features = 15)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy Random Forest - fast text average:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
